\section{Running the pipeline}
The automated pipeline is run after the data has been obtained at the telescope. It operates on the raw ULTRACAM data, reducing it and preparing output files that are used for the Web browsing interface. The pipeline can be run anytime after the data has been recorded and is therefore useful for browsing and sharing ULTRACAM observations immediately after performing the observations, or much later, when wishing to reduce the data for a run that exists in the ULTRACAM archive.

\subsection{Prerequisites}
The pipeline is written in the Python programming language and needs a working Python environment. It is currently running on Python version 2.6.9, but has also been tested on version 2.7.6. Within the Python path, the following fairly well-known Python libraries should be installed. 
\begin{itemize}
  \item \emph{Numpy} NumPy is a well-known package for scientific computing with Python. It is available from \url{http://www.numpy.org}.
  \item \emph{Astropy} Astropy Project is a community effort to develop a single core package for Astronomy in Python and foster interoperability between Python astronomy packages. Available at \url{http://www.astropy.org/}.
  \item \emph{Matplotlib} matplotlib is a python 2D plotting library itcan be used in python scripts, the python and ipython shell. It is available at  \url{http://matplotlib.org/}
  \item \emph{Image} The Image package contains the Python Imaging Library. This library is used for loading, creating and modifying bitmap images and is used by the pipeline to create the .PNG images that are used on the web pages. It can be found at \url{http://effbot.org/imagingbook/pil-index.htm}.
  \item \emph{Jinja} The Jinja2 package contains tools for creating and using template files and merging them with dynamic data. The pipeline uses this module to create the HTML files for the web site. It can be found at \url{http://jinja.pocoo.org/}.

\end{itemize}
Along with these packages, the following standard Python modules are also used by the pipeline. These packages are nearly always included by default in Python distributions.
\begin{itemize}
  \item \emph{Math} A module to perform some basic mathematical operations.
  \item \emph{Argparse} A module that aids the creation of 'command-line parameters' for the scripts in the pipeline. 
  \item \emph{Time} A module for performing time functions and operations.
  \item \emph{DateTime} A module for formatting and manageing date and calendar objects.
  \item \emph{JSON} A module for reading, writing and parsing JSON-formatted data objects. 
\end{itemize}

The source extration and flux measurement activity in the pipeline is performed by the third party software, called \emph{SExtractor}, \cite{bertin}. SExtractor can be downloaded and installed from \url{http://www.astromatic.net/software/sextractor}. If downloading and compiling from the source, there is a good guide available at: \url{http://wiki.ipb.ac.rs/index.php/SExtractor_installation}. 

In order to serve the web site, a web server is needed. Fortunately, since the web site consists purely of static files, a simple HTTP server is required. For example, an instance of the Apache web server with no server-side add-ons is perfectly adequate. 

\subsection{Installing the Python code}
The core code of the automated pipeline exists in the 'git' repository. It is therefore easy to download the code into a local directory, by typing the command: \texttt{git clone https://github.com/rashley2712/ucambuilder}.  This will create a sub directory called \texttt{ucambuilder} which will contain all of the required Python code for running the automated pipeline. Since, it is likely that you will not be running the pipeline from this directory, an important next step is to add this directory to your \texttt{PATH} and \texttt{PYTHONPATH} environment variables. 

\subsection{Config file}
It is a good idea to create a separate directory to keep configuration files and temporary files. It is also good practice to run the pipeline from this folder as it will, by default, look in the local directory for the configuration files. In this folder, you should create a few configuration files that you can modify as desired before running the pipeline. In order to get a pre-built set of configuration files, you can use a 'git' repository to create and download a folder with the default set. Typing \texttt{git clone https://github.com/rashley2712/ultracam-auto} will download the configuration files into a folder called \texttt{ultracam-auto}. 

The following files are needed as configuration files: 
\begin{itemize}
  \item \emph{ucambuilder.conf} This is the pipeline's main configuration file and is used to store the parameters that specify where the pipeline should look for the raw data, where it should write the output files, etc. This is discussed in more detail in the next section of this document. 
  \item \emph{default.sex} Is the configuration file that is loaded when {SExtractor}.  This files contains many parameters that instructs {SExtractor} on how to perform the source extraction and flux calculation in the image. More details on these parameters can be found in the {Sextractor} User Manual \footnote{\url{https://www.astromatic.net/pubsvn/software/sextractor/trunk/doc/sextractor.pdf}}. 
  \item \emph{default.param} This file lists the columns that we want {SExtractor} to include in the output catalog. These columns are read by the automated pipeline in order to build up the master catalog. We need {SExtractor} to output flux measurements, pixel coordinates and measurement flags. Generally these parameters do not need to be edited. 
  \item \emph{default.conv} This file defines the profile of the convolution filter that {Sextractor} applies to the image before source extraction. 
\end{itemize}

\subsection{ucambuilder.conf}
A sample of the main configuration file for the automated pipeline is shown below.
\begin{lstlisting}
DEBUG   1       # The debug level to be used by the various scripts. Can be 1, 2, 3
SITE_PATH       /storage/astro2/www/phrnaw/sitedev      # The path to the website
ULTRACAMRAW     /storage/astro1/phsaap/ultracam/raw_data        # Path to the Ultracam raw data
WRITE_FITS      0       # Write a fits file or not?
WRITE_JSON      1       # Write a fits file or not?
KEEP_TMP_FILES  0       # Keep the temporary (sextractor) files?
RUNTEMPLATE     /storage/astro2/www/phrnaw/sitedev/sitecode/runxxx.jinja
DAYTEMPLATE     /storage/astro2/www/phrnaw/sitedev/sitecode/day-xxxx-xx-xx.jinja
MOVIE_TMP_PATH  /tmp/movie
MINPIXELDISTANCE        10
FONT    /usr/share/fonts/truetype/arial.ttf
RUNINFO         /storage/astro1/phsaap/ultracam/logs/ultra.json
WORKINGDIR      /storage/astro2/phrnaw/workingdir
ROOTURL         http://deneb.astro.warwick.ac.uk/phrnaw/sitedev/
SEX_MAGNITUDE   FLUX_AUTO
COMPARISON_THRESHOLD    95
\end{lstlisting}
These parameters should be modified before running the pipeline.
\begin{itemize}
\item \texttt{SITE\_PATH} Specifies where the document root for the web folder is. The pipeline will write the HTML and JSON files to this folder. For each date in the archive, the pipeline will create sub-directories in the format \texttt{YYYY-MM-DD}. A web server should be configured to serve HTTP requests from this folder. 
\item \texttt{ULTRACAMRAW} This should point to the root folder where the raw ULTRACAM data is stored. Within this folder there will be sub-folders corresponding to each date on which the ULTRACAM was active. These folders will contain \texttt{.dat} and \texttt{.xml} files corresponding to each run recording during that observing night.  
\item \texttt{ROOTURL} Specifies where the \texttt{SITE\_PATH} is accessed in URL space. In other words, this is the URL to the web site that is configured to serve files from the \texttt{SITE\_PATH} folder. 
\item \texttt{SITE\_PATH}
\end{itemize}

\subsection{objectdbcreator.py}

This is the most important script in the automated pipeline. It takes the raw image data in the ULTRACAM archive and sends it to SExtractor for processing. Based on the SExtractor output, it compiles and maintains a list of objects across all of the frames and each of the channels. These are given as three output catalogs when the script finishes running. 

\subsubsection{Command line parameters}
objectdbcreator.py takes the following command line parameters:
\begin{itemize}
  \item \texttt{runName} This is a path to the \texttt{.xml} and \texttt{.dat} for a specific run and is specified in the format \texttt{YYYY-MM-DD/runXXX}  (for example \texttt{2013-07-21/run011}).
  \item \texttt{-d[n] --debug [n]} Use this parameter to determine how much output you would like to see while the program is running. There are 3 debug levels, \emph{1} is silent (except for errors) and is the default debug level; \emph{2} shows general progress of the pipeline; \emph{3} shows detailed info to help with debugging. Note that the default is `silent' and therefore, unless there are errors, you will not see anything on the command line and a long run through the data could last an hour or more. It is recommended that you use \texttt{-d2} in most cases. 
  \item \texttt{-n[n] --numframes [n]} Specifies the number of frames you would like the script to process. The default is all of the frames in the run. Making this number smaller is useful for running a quick test. For example, \texttt{-n100} will run through 100 frames only.
   \item \texttt{-s[n] --startframe [n]} Specifies which frame to start at. The default is frame 1 (the first frame in the run). 
  \item \texttt{-c[filename] --configfile [filename]} Allows you to specify an alternative configuration file. By default, the script will look for a file called ``ultracam.conf" in the local directory. 
  \item \texttt{-C[r,g,b] --channels [r,g,b]} Which channels to operate the pipeline over. By default, the script will process all three channels, namely, r, g, and b. This parameter allows you to specify a subset of these channels. For example, you could omit the processing of the `green channel' by passing in \texttt{-Crb}. 
  \item \texttt{-p --preview} Specifying this parameter enables a preview window for each frame and each channel using \emph{Matplotlib}. This allows you to see each frame as it is being processed. The colour palettes match the channel, red for r, green for g and blue for b. The preview window also draws a green circle around each object that SExtractor has identified on that particular frame. Warning: This preview slows down the pipeline significantly so should only be used for information and debugging purposes. 
  \item \texttt{-t[n] --sleep [n]} Time to pause (in seconds) between the processing of each frame. Useful for debugging in `preview' mode. 
  \item \texttt{-r --crop} For `preview' mode, crop the windows to show only the areas that were not masked in the original data. Useful for runs where the windows are fairly small. 
\end{itemize}

\subsubsection{Output while running}
If the \texttt{--debug} option is left to the default value of \texttt{1} then the output will be mostly \emph{silent} with only errors appearing in \texttt{stdout}. This mode is designed for use during the running of the pipeline across a complete night where we want to suppress a lot of the output. If you are running \emph{objectdbcreator.py} in standalone mode, then \texttt{-d2} is recommended. 

The output of the script with \texttt{-d2} set looks like this:

\begin{lstlisting}
[10:31:25] 00:10:22 Frame: [1681,1681 87%] MJD:56495.1395466 r:1899 g:1030 b:551 
[10:31:27] 00:10:19 Frame: [1682,1682 87%] MJD:56495.1396132 r:1900 g:1030 b:551 
[10:31:29] 00:10:17 Frame: [1683,1683 87%] MJD:56495.1396799 r:1900 g:1030 b:551 
[10:31:32] 00:10:14 Frame: [1684,1684 87%] MJD:56495.1397465 r:1900 g:1030 b:552 
\end{lstlisting}

Where, 


\begin{itemize}
  \item \texttt{[10:31:25]} is the current time, in HH-MM-SS format;
  \item \texttt{[00:10:22]} is the estimated time remaining until the run has finish being processed in HH-MM-SS format;
  \item \texttt{Frame:[1681, 1681 87\%]} The first number is the absoluted frame number being processed (starts at first frame of the run = 1), the second number is the relative frame being processed (different if the start frame was not = 1), and the percentage completed;
  \item \texttt{MJD:56495.1395466} is the MJD for this frame;
  \item \texttt{r:1899 g: 1030 b:551} shows the number of objects being tracked in each of the r, g, b channels.
\end{itemize}


\section{Using the archive} 

User manual for the web interface.


